Генерация текста с GPT-2

Этот проект демонстрирует генерацию текста с использованием модели GPT-2 из библиотеки transformers от Hugging Face. В данном ноутбуке реализована установка зависимостей, загрузка модели и токенизатора, ввод начального текста (промпта), генерация текста с настраиваемыми параметрами и отображение результатов. Также включен интерактивный виджет для динамического ввода данных.

Установка и запуск

Требования





Python 3.8 или выше



Установленные библиотеки: transformers, torch, ipywidgets

Установка зависимостей

Для установки необходимых библиотек выполните следующую команду:

pip install transformers torch ipywidgets

Использование





Загрузка модели и токенизатора: Код загружает предварительно обученную модель GPT-2 и соответствующий токенизатор из библиотеки Hugging Face.



Генерация текста: Функция generate_text принимает начальный текст (промпт) и параметры:





max_length: максимальная длина генерируемого текста (по умолчанию: 50 токенов).



temperature: контролирует случайность текста (меньше — более предсказуемый, больше — более креативный; по умолчанию: 0.8).



top_k: ограничивает выборку K наиболее вероятными токенами (по умолчанию: 50).



do_sample: если включено, используется выборка; если выключено — жадное декодирование (по умолчанию: True).



Интерактивный интерфейс: Интерактивный виджет позволяет:





Вводить начальный текст (промпт) в текстовом поле.



Настраивать параметры генерации с помощью ползунков (max_length, temperature, top_k) и флажка (do_sample).



Генерировать текст нажатием кнопки "Generate Text".

Запуск проекта





Склонируйте репозиторий:

git clone <URL_репозитория>
cd <название_папки>



Запустите Jupyter Notebook:

jupyter notebook



Откройте файл text_generation_gpt2.ipynb и выполните ячейки кода по порядку.



В последней ячейке появится интерактивный интерфейс, где вы можете:





Ввести начальный текст (например, "Once upon a time").



Настроить параметры генерации.



Нажать кнопку "Generate Text" для создания текста.

Пример ввода и вывода

Ввод:





Промпт: "Once upon a time"



Параметры: max_length=50, temperature=0.8, top_k=50, do_sample=True

Вывод: Сгенерированный текст, продолжающий введенный промпт, будет отображен в области вывода.

Параметры генерации





max_length: Максимальное количество токенов в генерируемом тексте (по умолчанию: 50).



temperature: Контролирует степень случайности текста (по умолчанию: 0.8).



top_k: Ограничивает выборку K наиболее вероятными токенами (по умолчанию: 50).



do_sample: Включает или отключает выборку для генерации (по умолчанию: True).

Примечания





Для работы проекта требуется подключение к интернету для загрузки модели GPT-2.



Для оптимальной производительности рекомендуется использовать GPU, хотя проект работает и на CPU.



Если вы используете Jupyter Notebook в среде без поддержки виджетов (например, VS Code), могут потребоваться дополнительные настройки для отображения интерактивных элементов.